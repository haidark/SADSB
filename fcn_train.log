I0204 16:15:23.984793  8495 caffe.cpp:183] Using GPUs 0
I0204 16:15:24.136394  8495 solver.cpp:54] Initializing solver from parameters: 
train_net: "fcn_train.prototxt"
test_net: "fcn_test.prototxt"
test_iter: 26
test_interval: 200
base_lr: 0.01
display: 200
max_iter: 15000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
snapshot: 2500
snapshot_prefix: "./model_logs/fcn"
device_id: 0
random_seed: 5
test_initialization: true
average_loss: 200
stepvalue: 10000
I0204 16:15:24.137141  8495 solver.cpp:86] Creating training net from train_net file: fcn_train.prototxt
I0204 16:15:24.137894  8495 net.cpp:50] Initializing net from parameters: 
name: "FCN"
force_backward: true
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  transform_param {
    mirror: false
    crop_size: 0
    mean_value: 77
  }
  data_param {
    source: "train_images_lmdb/"
    batch_size: 1
    backend: LMDB
  }
}
layer {
  name: "label"
  type: "Data"
  top: "label"
  data_param {
    source: "train_labels_lmdb/"
    batch_size: 1
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 100
    pad: 50
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 200
    pad: 0
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 300
    pad: 0
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 300
    pad: 0
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "drop"
  type: "Dropout"
  bottom: "conv4"
  top: "conv4"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "score_classes"
  type: "Convolution"
  bottom: "conv4"
  top: "score_classes"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "upscore"
  type: "Deconvolution"
  bottom: "score_classes"
  top: "upscore"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    bias_term: true
    pad: 8
    kernel_size: 31
    stride: 16
    weight_filler {
      type: "bilinear"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "score"
  type: "Crop"
  bottom: "upscore"
  bottom: "data"
  top: "score"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
  loss_param {
    normalize: true
  }
}
I0204 16:15:24.137998  8495 layer_factory.hpp:76] Creating layer data
I0204 16:15:24.139379  8495 net.cpp:111] Creating Layer data
I0204 16:15:24.139389  8495 net.cpp:434] data -> data
I0204 16:15:24.141121  8500 db_lmdb.cpp:22] Opened lmdb train_images_lmdb/
I0204 16:15:24.145236  8495 data_layer.cpp:44] output data size: 1,1,256,256
I0204 16:15:24.166388  8495 net.cpp:156] Setting up data
I0204 16:15:24.166420  8495 net.cpp:164] Top shape: 1 1 256 256 (65536)
I0204 16:15:24.166430  8495 layer_factory.hpp:76] Creating layer data_data_0_split
I0204 16:15:24.167007  8495 net.cpp:111] Creating Layer data_data_0_split
I0204 16:15:24.167016  8495 net.cpp:478] data_data_0_split <- data
I0204 16:15:24.167023  8495 net.cpp:434] data_data_0_split -> data_data_0_split_0
I0204 16:15:24.167032  8495 net.cpp:434] data_data_0_split -> data_data_0_split_1
I0204 16:15:24.167865  8495 net.cpp:156] Setting up data_data_0_split
I0204 16:15:24.167877  8495 net.cpp:164] Top shape: 1 1 256 256 (65536)
I0204 16:15:24.167882  8495 net.cpp:164] Top shape: 1 1 256 256 (65536)
I0204 16:15:24.167887  8495 layer_factory.hpp:76] Creating layer label
I0204 16:15:24.167934  8495 net.cpp:111] Creating Layer label
I0204 16:15:24.167942  8495 net.cpp:434] label -> label
I0204 16:15:24.169255  8502 db_lmdb.cpp:22] Opened lmdb train_labels_lmdb/
I0204 16:15:24.172713  8495 data_layer.cpp:44] output data size: 1,1,256,256
I0204 16:15:24.174108  8495 net.cpp:156] Setting up label
I0204 16:15:24.174125  8495 net.cpp:164] Top shape: 1 1 256 256 (65536)
I0204 16:15:24.174131  8495 layer_factory.hpp:76] Creating layer conv1
I0204 16:15:24.174144  8495 net.cpp:111] Creating Layer conv1
I0204 16:15:24.174149  8495 net.cpp:478] conv1 <- data_data_0_split_0
I0204 16:15:24.174161  8495 net.cpp:434] conv1 -> conv1
I0204 16:15:24.294744  8495 net.cpp:156] Setting up conv1
I0204 16:15:24.294791  8495 net.cpp:164] Top shape: 1 100 176 176 (3097600)
I0204 16:15:24.294811  8495 layer_factory.hpp:76] Creating layer relu1
I0204 16:15:24.294832  8495 net.cpp:111] Creating Layer relu1
I0204 16:15:24.294838  8495 net.cpp:478] relu1 <- conv1
I0204 16:15:24.294844  8495 net.cpp:420] relu1 -> conv1 (in-place)
I0204 16:15:24.295060  8495 net.cpp:156] Setting up relu1
I0204 16:15:24.295073  8495 net.cpp:164] Top shape: 1 100 176 176 (3097600)
I0204 16:15:24.295078  8495 layer_factory.hpp:76] Creating layer pool1
I0204 16:15:24.295086  8495 net.cpp:111] Creating Layer pool1
I0204 16:15:24.295091  8495 net.cpp:478] pool1 <- conv1
I0204 16:15:24.295096  8495 net.cpp:434] pool1 -> pool1
I0204 16:15:24.295238  8495 net.cpp:156] Setting up pool1
I0204 16:15:24.295248  8495 net.cpp:164] Top shape: 1 100 88 88 (774400)
I0204 16:15:24.295251  8495 layer_factory.hpp:76] Creating layer conv2
I0204 16:15:24.295260  8495 net.cpp:111] Creating Layer conv2
I0204 16:15:24.295264  8495 net.cpp:478] conv2 <- pool1
I0204 16:15:24.295270  8495 net.cpp:434] conv2 -> conv2
I0204 16:15:24.308805  8495 net.cpp:156] Setting up conv2
I0204 16:15:24.308846  8495 net.cpp:164] Top shape: 1 200 42 42 (352800)
I0204 16:15:24.308861  8495 layer_factory.hpp:76] Creating layer relu2
I0204 16:15:24.308871  8495 net.cpp:111] Creating Layer relu2
I0204 16:15:24.308874  8495 net.cpp:478] relu2 <- conv2
I0204 16:15:24.308889  8495 net.cpp:420] relu2 -> conv2 (in-place)
I0204 16:15:24.309010  8495 net.cpp:156] Setting up relu2
I0204 16:15:24.309017  8495 net.cpp:164] Top shape: 1 200 42 42 (352800)
I0204 16:15:24.309021  8495 layer_factory.hpp:76] Creating layer pool2
I0204 16:15:24.309029  8495 net.cpp:111] Creating Layer pool2
I0204 16:15:24.309033  8495 net.cpp:478] pool2 <- conv2
I0204 16:15:24.309044  8495 net.cpp:434] pool2 -> pool2
I0204 16:15:24.309259  8495 net.cpp:156] Setting up pool2
I0204 16:15:24.309269  8495 net.cpp:164] Top shape: 1 200 21 21 (88200)
I0204 16:15:24.309274  8495 layer_factory.hpp:76] Creating layer conv3
I0204 16:15:24.309281  8495 net.cpp:111] Creating Layer conv3
I0204 16:15:24.309285  8495 net.cpp:478] conv3 <- pool2
I0204 16:15:24.309291  8495 net.cpp:434] conv3 -> conv3
I0204 16:15:24.323770  8495 net.cpp:156] Setting up conv3
I0204 16:15:24.323810  8495 net.cpp:164] Top shape: 1 300 19 19 (108300)
I0204 16:15:24.323825  8495 layer_factory.hpp:76] Creating layer relu3
I0204 16:15:24.323834  8495 net.cpp:111] Creating Layer relu3
I0204 16:15:24.323839  8495 net.cpp:478] relu3 <- conv3
I0204 16:15:24.323854  8495 net.cpp:420] relu3 -> conv3 (in-place)
I0204 16:15:24.323995  8495 net.cpp:156] Setting up relu3
I0204 16:15:24.324004  8495 net.cpp:164] Top shape: 1 300 19 19 (108300)
I0204 16:15:24.324009  8495 layer_factory.hpp:76] Creating layer conv4
I0204 16:15:24.324026  8495 net.cpp:111] Creating Layer conv4
I0204 16:15:24.324030  8495 net.cpp:478] conv4 <- conv3
I0204 16:15:24.324035  8495 net.cpp:434] conv4 -> conv4
I0204 16:15:24.344835  8495 net.cpp:156] Setting up conv4
I0204 16:15:24.344873  8495 net.cpp:164] Top shape: 1 300 17 17 (86700)
I0204 16:15:24.344894  8495 layer_factory.hpp:76] Creating layer relu4
I0204 16:15:24.344904  8495 net.cpp:111] Creating Layer relu4
I0204 16:15:24.344909  8495 net.cpp:478] relu4 <- conv4
I0204 16:15:24.344915  8495 net.cpp:420] relu4 -> conv4 (in-place)
I0204 16:15:24.345152  8495 net.cpp:156] Setting up relu4
I0204 16:15:24.345163  8495 net.cpp:164] Top shape: 1 300 17 17 (86700)
I0204 16:15:24.345168  8495 layer_factory.hpp:76] Creating layer drop
I0204 16:15:24.345175  8495 net.cpp:111] Creating Layer drop
I0204 16:15:24.345178  8495 net.cpp:478] drop <- conv4
I0204 16:15:24.345183  8495 net.cpp:420] drop -> conv4 (in-place)
I0204 16:15:24.345192  8495 net.cpp:156] Setting up drop
I0204 16:15:24.345196  8495 net.cpp:164] Top shape: 1 300 17 17 (86700)
I0204 16:15:24.345199  8495 layer_factory.hpp:76] Creating layer score_classes
I0204 16:15:24.345207  8495 net.cpp:111] Creating Layer score_classes
I0204 16:15:24.345211  8495 net.cpp:478] score_classes <- conv4
I0204 16:15:24.345217  8495 net.cpp:434] score_classes -> score_classes
I0204 16:15:24.345787  8495 net.cpp:156] Setting up score_classes
I0204 16:15:24.345798  8495 net.cpp:164] Top shape: 1 2 17 17 (578)
I0204 16:15:24.345808  8495 layer_factory.hpp:76] Creating layer upscore
I0204 16:15:24.345815  8495 net.cpp:111] Creating Layer upscore
I0204 16:15:24.345818  8495 net.cpp:478] upscore <- score_classes
I0204 16:15:24.345824  8495 net.cpp:434] upscore -> upscore
I0204 16:15:24.346293  8495 net.cpp:156] Setting up upscore
I0204 16:15:24.346303  8495 net.cpp:164] Top shape: 1 2 271 271 (146882)
I0204 16:15:24.346310  8495 layer_factory.hpp:76] Creating layer score
I0204 16:15:24.346318  8495 net.cpp:111] Creating Layer score
I0204 16:15:24.346321  8495 net.cpp:478] score <- upscore
I0204 16:15:24.346325  8495 net.cpp:478] score <- data_data_0_split_1
I0204 16:15:24.346331  8495 net.cpp:434] score -> score
I0204 16:15:24.346365  8495 net.cpp:156] Setting up score
I0204 16:15:24.346370  8495 net.cpp:164] Top shape: 1 2 256 256 (131072)
I0204 16:15:24.346374  8495 layer_factory.hpp:76] Creating layer loss
I0204 16:15:24.346380  8495 net.cpp:111] Creating Layer loss
I0204 16:15:24.346385  8495 net.cpp:478] loss <- score
I0204 16:15:24.346388  8495 net.cpp:478] loss <- label
I0204 16:15:24.346392  8495 net.cpp:434] loss -> loss
I0204 16:15:24.346401  8495 layer_factory.hpp:76] Creating layer loss
I0204 16:15:24.346736  8495 net.cpp:156] Setting up loss
I0204 16:15:24.346746  8495 net.cpp:164] Top shape: (1)
I0204 16:15:24.346750  8495 net.cpp:169]     with loss weight 1
I0204 16:15:24.346765  8495 net.cpp:237] loss needs backward computation.
I0204 16:15:24.346768  8495 net.cpp:237] score needs backward computation.
I0204 16:15:24.346771  8495 net.cpp:237] upscore needs backward computation.
I0204 16:15:24.346779  8495 net.cpp:237] score_classes needs backward computation.
I0204 16:15:24.346791  8495 net.cpp:237] drop needs backward computation.
I0204 16:15:24.346793  8495 net.cpp:237] relu4 needs backward computation.
I0204 16:15:24.346796  8495 net.cpp:237] conv4 needs backward computation.
I0204 16:15:24.346799  8495 net.cpp:237] relu3 needs backward computation.
I0204 16:15:24.346802  8495 net.cpp:237] conv3 needs backward computation.
I0204 16:15:24.346806  8495 net.cpp:237] pool2 needs backward computation.
I0204 16:15:24.346808  8495 net.cpp:237] relu2 needs backward computation.
I0204 16:15:24.346812  8495 net.cpp:237] conv2 needs backward computation.
I0204 16:15:24.346815  8495 net.cpp:237] pool1 needs backward computation.
I0204 16:15:24.346819  8495 net.cpp:237] relu1 needs backward computation.
I0204 16:15:24.346822  8495 net.cpp:237] conv1 needs backward computation.
I0204 16:15:24.346825  8495 net.cpp:241] label does not need backward computation.
I0204 16:15:24.346829  8495 net.cpp:241] data_data_0_split does not need backward computation.
I0204 16:15:24.346832  8495 net.cpp:241] data does not need backward computation.
I0204 16:15:24.346837  8495 net.cpp:284] This network produces output loss
I0204 16:15:24.346849  8495 net.cpp:298] Network initialization done.
I0204 16:15:24.346853  8495 net.cpp:299] Memory required for data: 35123108
I0204 16:15:24.347486  8495 solver.cpp:186] Creating test net (#0) specified by test_net file: fcn_test.prototxt
I0204 16:15:24.347656  8495 net.cpp:50] Initializing net from parameters: 
name: "FCN"
force_backward: true
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  transform_param {
    mirror: false
    crop_size: 0
    mean_value: 77
  }
  data_param {
    source: "val_images_lmdb/"
    batch_size: 1
    backend: LMDB
  }
}
layer {
  name: "label"
  type: "Data"
  top: "label"
  data_param {
    source: "val_labels_lmdb/"
    batch_size: 1
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 100
    pad: 50
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 200
    pad: 0
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 300
    pad: 0
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 300
    pad: 0
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "drop"
  type: "Dropout"
  bottom: "conv4"
  top: "conv4"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "score_classes"
  type: "Convolution"
  bottom: "conv4"
  top: "score_classes"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "upscore"
  type: "Deconvolution"
  bottom: "score_classes"
  top: "upscore"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    bias_term: true
    pad: 8
    kernel_size: 31
    stride: 16
    weight_filler {
      type: "bilinear"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "score"
  type: "Crop"
  bottom: "upscore"
  bottom: "data"
  top: "score"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
  loss_param {
    normalize: true
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "accuracy"
}
I0204 16:15:24.347744  8495 layer_factory.hpp:76] Creating layer data
I0204 16:15:24.347803  8495 net.cpp:111] Creating Layer data
I0204 16:15:24.347817  8495 net.cpp:434] data -> data
I0204 16:15:24.348853  8504 db_lmdb.cpp:22] Opened lmdb val_images_lmdb/
I0204 16:15:24.350664  8495 data_layer.cpp:44] output data size: 1,1,256,256
I0204 16:15:24.351296  8495 net.cpp:156] Setting up data
I0204 16:15:24.351310  8495 net.cpp:164] Top shape: 1 1 256 256 (65536)
I0204 16:15:24.351315  8495 layer_factory.hpp:76] Creating layer data_data_0_split
I0204 16:15:24.351325  8495 net.cpp:111] Creating Layer data_data_0_split
I0204 16:15:24.351330  8495 net.cpp:478] data_data_0_split <- data
I0204 16:15:24.351336  8495 net.cpp:434] data_data_0_split -> data_data_0_split_0
I0204 16:15:24.351343  8495 net.cpp:434] data_data_0_split -> data_data_0_split_1
I0204 16:15:24.351351  8495 net.cpp:156] Setting up data_data_0_split
I0204 16:15:24.351356  8495 net.cpp:164] Top shape: 1 1 256 256 (65536)
I0204 16:15:24.351361  8495 net.cpp:164] Top shape: 1 1 256 256 (65536)
I0204 16:15:24.351364  8495 layer_factory.hpp:76] Creating layer label
I0204 16:15:24.351395  8495 net.cpp:111] Creating Layer label
I0204 16:15:24.351402  8495 net.cpp:434] label -> label
I0204 16:15:24.353723  8506 db_lmdb.cpp:22] Opened lmdb val_labels_lmdb/
I0204 16:15:24.355005  8495 data_layer.cpp:44] output data size: 1,1,256,256
I0204 16:15:24.355556  8495 net.cpp:156] Setting up label
I0204 16:15:24.355571  8495 net.cpp:164] Top shape: 1 1 256 256 (65536)
I0204 16:15:24.355576  8495 layer_factory.hpp:76] Creating layer label_label_0_split
I0204 16:15:24.355586  8495 net.cpp:111] Creating Layer label_label_0_split
I0204 16:15:24.355590  8495 net.cpp:478] label_label_0_split <- label
I0204 16:15:24.355597  8495 net.cpp:434] label_label_0_split -> label_label_0_split_0
I0204 16:15:24.355607  8495 net.cpp:434] label_label_0_split -> label_label_0_split_1
I0204 16:15:24.355613  8495 net.cpp:156] Setting up label_label_0_split
I0204 16:15:24.355618  8495 net.cpp:164] Top shape: 1 1 256 256 (65536)
I0204 16:15:24.355623  8495 net.cpp:164] Top shape: 1 1 256 256 (65536)
I0204 16:15:24.355626  8495 layer_factory.hpp:76] Creating layer conv1
I0204 16:15:24.355635  8495 net.cpp:111] Creating Layer conv1
I0204 16:15:24.355639  8495 net.cpp:478] conv1 <- data_data_0_split_0
I0204 16:15:24.355644  8495 net.cpp:434] conv1 -> conv1
I0204 16:15:24.356755  8495 net.cpp:156] Setting up conv1
I0204 16:15:24.356767  8495 net.cpp:164] Top shape: 1 100 176 176 (3097600)
I0204 16:15:24.356777  8495 layer_factory.hpp:76] Creating layer relu1
I0204 16:15:24.356791  8495 net.cpp:111] Creating Layer relu1
I0204 16:15:24.356802  8495 net.cpp:478] relu1 <- conv1
I0204 16:15:24.356807  8495 net.cpp:420] relu1 -> conv1 (in-place)
I0204 16:15:24.356999  8495 net.cpp:156] Setting up relu1
I0204 16:15:24.357008  8495 net.cpp:164] Top shape: 1 100 176 176 (3097600)
I0204 16:15:24.357013  8495 layer_factory.hpp:76] Creating layer pool1
I0204 16:15:24.357019  8495 net.cpp:111] Creating Layer pool1
I0204 16:15:24.357023  8495 net.cpp:478] pool1 <- conv1
I0204 16:15:24.357029  8495 net.cpp:434] pool1 -> pool1
I0204 16:15:24.357267  8495 net.cpp:156] Setting up pool1
I0204 16:15:24.357277  8495 net.cpp:164] Top shape: 1 100 88 88 (774400)
I0204 16:15:24.357281  8495 layer_factory.hpp:76] Creating layer conv2
I0204 16:15:24.357290  8495 net.cpp:111] Creating Layer conv2
I0204 16:15:24.357293  8495 net.cpp:478] conv2 <- pool1
I0204 16:15:24.357302  8495 net.cpp:434] conv2 -> conv2
I0204 16:15:24.370693  8495 net.cpp:156] Setting up conv2
I0204 16:15:24.370733  8495 net.cpp:164] Top shape: 1 200 42 42 (352800)
I0204 16:15:24.370755  8495 layer_factory.hpp:76] Creating layer relu2
I0204 16:15:24.370766  8495 net.cpp:111] Creating Layer relu2
I0204 16:15:24.370770  8495 net.cpp:478] relu2 <- conv2
I0204 16:15:24.370785  8495 net.cpp:420] relu2 -> conv2 (in-place)
I0204 16:15:24.370919  8495 net.cpp:156] Setting up relu2
I0204 16:15:24.370926  8495 net.cpp:164] Top shape: 1 200 42 42 (352800)
I0204 16:15:24.370930  8495 layer_factory.hpp:76] Creating layer pool2
I0204 16:15:24.370937  8495 net.cpp:111] Creating Layer pool2
I0204 16:15:24.370941  8495 net.cpp:478] pool2 <- conv2
I0204 16:15:24.370946  8495 net.cpp:434] pool2 -> pool2
I0204 16:15:24.371156  8495 net.cpp:156] Setting up pool2
I0204 16:15:24.371166  8495 net.cpp:164] Top shape: 1 200 21 21 (88200)
I0204 16:15:24.371170  8495 layer_factory.hpp:76] Creating layer conv3
I0204 16:15:24.371178  8495 net.cpp:111] Creating Layer conv3
I0204 16:15:24.371181  8495 net.cpp:478] conv3 <- pool2
I0204 16:15:24.371187  8495 net.cpp:434] conv3 -> conv3
I0204 16:15:24.385274  8495 net.cpp:156] Setting up conv3
I0204 16:15:24.385311  8495 net.cpp:164] Top shape: 1 300 19 19 (108300)
I0204 16:15:24.385334  8495 layer_factory.hpp:76] Creating layer relu3
I0204 16:15:24.385344  8495 net.cpp:111] Creating Layer relu3
I0204 16:15:24.385349  8495 net.cpp:478] relu3 <- conv3
I0204 16:15:24.385363  8495 net.cpp:420] relu3 -> conv3 (in-place)
I0204 16:15:24.385498  8495 net.cpp:156] Setting up relu3
I0204 16:15:24.385527  8495 net.cpp:164] Top shape: 1 300 19 19 (108300)
I0204 16:15:24.385532  8495 layer_factory.hpp:76] Creating layer conv4
I0204 16:15:24.385550  8495 net.cpp:111] Creating Layer conv4
I0204 16:15:24.385553  8495 net.cpp:478] conv4 <- conv3
I0204 16:15:24.385560  8495 net.cpp:434] conv4 -> conv4
I0204 16:15:24.406388  8495 net.cpp:156] Setting up conv4
I0204 16:15:24.406420  8495 net.cpp:164] Top shape: 1 300 17 17 (86700)
I0204 16:15:24.406431  8495 layer_factory.hpp:76] Creating layer relu4
I0204 16:15:24.406441  8495 net.cpp:111] Creating Layer relu4
I0204 16:15:24.406446  8495 net.cpp:478] relu4 <- conv4
I0204 16:15:24.406451  8495 net.cpp:420] relu4 -> conv4 (in-place)
I0204 16:15:24.406743  8495 net.cpp:156] Setting up relu4
I0204 16:15:24.406754  8495 net.cpp:164] Top shape: 1 300 17 17 (86700)
I0204 16:15:24.406757  8495 layer_factory.hpp:76] Creating layer drop
I0204 16:15:24.406765  8495 net.cpp:111] Creating Layer drop
I0204 16:15:24.406769  8495 net.cpp:478] drop <- conv4
I0204 16:15:24.406774  8495 net.cpp:420] drop -> conv4 (in-place)
I0204 16:15:24.406781  8495 net.cpp:156] Setting up drop
I0204 16:15:24.406785  8495 net.cpp:164] Top shape: 1 300 17 17 (86700)
I0204 16:15:24.406790  8495 layer_factory.hpp:76] Creating layer score_classes
I0204 16:15:24.406796  8495 net.cpp:111] Creating Layer score_classes
I0204 16:15:24.406800  8495 net.cpp:478] score_classes <- conv4
I0204 16:15:24.406805  8495 net.cpp:434] score_classes -> score_classes
I0204 16:15:24.407488  8495 net.cpp:156] Setting up score_classes
I0204 16:15:24.407505  8495 net.cpp:164] Top shape: 1 2 17 17 (578)
I0204 16:15:24.407519  8495 layer_factory.hpp:76] Creating layer upscore
I0204 16:15:24.407531  8495 net.cpp:111] Creating Layer upscore
I0204 16:15:24.407534  8495 net.cpp:478] upscore <- score_classes
I0204 16:15:24.407539  8495 net.cpp:434] upscore -> upscore
I0204 16:15:24.407987  8495 net.cpp:156] Setting up upscore
I0204 16:15:24.407997  8495 net.cpp:164] Top shape: 1 2 271 271 (146882)
I0204 16:15:24.408004  8495 layer_factory.hpp:76] Creating layer score
I0204 16:15:24.408010  8495 net.cpp:111] Creating Layer score
I0204 16:15:24.408013  8495 net.cpp:478] score <- upscore
I0204 16:15:24.408018  8495 net.cpp:478] score <- data_data_0_split_1
I0204 16:15:24.408022  8495 net.cpp:434] score -> score
I0204 16:15:24.408047  8495 net.cpp:156] Setting up score
I0204 16:15:24.408051  8495 net.cpp:164] Top shape: 1 2 256 256 (131072)
I0204 16:15:24.408056  8495 layer_factory.hpp:76] Creating layer score_score_0_split
I0204 16:15:24.408061  8495 net.cpp:111] Creating Layer score_score_0_split
I0204 16:15:24.408063  8495 net.cpp:478] score_score_0_split <- score
I0204 16:15:24.408069  8495 net.cpp:434] score_score_0_split -> score_score_0_split_0
I0204 16:15:24.408076  8495 net.cpp:434] score_score_0_split -> score_score_0_split_1
I0204 16:15:24.408082  8495 net.cpp:156] Setting up score_score_0_split
I0204 16:15:24.408087  8495 net.cpp:164] Top shape: 1 2 256 256 (131072)
I0204 16:15:24.408092  8495 net.cpp:164] Top shape: 1 2 256 256 (131072)
I0204 16:15:24.408094  8495 layer_factory.hpp:76] Creating layer loss
I0204 16:15:24.408100  8495 net.cpp:111] Creating Layer loss
I0204 16:15:24.408103  8495 net.cpp:478] loss <- score_score_0_split_0
I0204 16:15:24.408107  8495 net.cpp:478] loss <- label_label_0_split_0
I0204 16:15:24.408113  8495 net.cpp:434] loss -> loss
I0204 16:15:24.408118  8495 layer_factory.hpp:76] Creating layer loss
I0204 16:15:24.408444  8495 net.cpp:156] Setting up loss
I0204 16:15:24.408454  8495 net.cpp:164] Top shape: (1)
I0204 16:15:24.408457  8495 net.cpp:169]     with loss weight 1
I0204 16:15:24.408468  8495 layer_factory.hpp:76] Creating layer accuracy
I0204 16:15:24.408473  8495 net.cpp:111] Creating Layer accuracy
I0204 16:15:24.408476  8495 net.cpp:478] accuracy <- score_score_0_split_1
I0204 16:15:24.408483  8495 net.cpp:478] accuracy <- label_label_0_split_1
I0204 16:15:24.408488  8495 net.cpp:434] accuracy -> accuracy
I0204 16:15:24.408494  8495 net.cpp:156] Setting up accuracy
I0204 16:15:24.408499  8495 net.cpp:164] Top shape: (1)
I0204 16:15:24.408502  8495 net.cpp:241] accuracy does not need backward computation.
I0204 16:15:24.408505  8495 net.cpp:237] loss needs backward computation.
I0204 16:15:24.408509  8495 net.cpp:237] score_score_0_split needs backward computation.
I0204 16:15:24.408514  8495 net.cpp:237] score needs backward computation.
I0204 16:15:24.408516  8495 net.cpp:237] upscore needs backward computation.
I0204 16:15:24.408520  8495 net.cpp:237] score_classes needs backward computation.
I0204 16:15:24.408524  8495 net.cpp:237] drop needs backward computation.
I0204 16:15:24.408526  8495 net.cpp:237] relu4 needs backward computation.
I0204 16:15:24.408529  8495 net.cpp:237] conv4 needs backward computation.
I0204 16:15:24.408532  8495 net.cpp:237] relu3 needs backward computation.
I0204 16:15:24.408535  8495 net.cpp:237] conv3 needs backward computation.
I0204 16:15:24.408540  8495 net.cpp:237] pool2 needs backward computation.
I0204 16:15:24.408542  8495 net.cpp:237] relu2 needs backward computation.
I0204 16:15:24.408545  8495 net.cpp:237] conv2 needs backward computation.
I0204 16:15:24.408548  8495 net.cpp:237] pool1 needs backward computation.
I0204 16:15:24.408552  8495 net.cpp:237] relu1 needs backward computation.
I0204 16:15:24.408555  8495 net.cpp:237] conv1 needs backward computation.
I0204 16:15:24.408560  8495 net.cpp:241] label_label_0_split does not need backward computation.
I0204 16:15:24.408562  8495 net.cpp:241] label does not need backward computation.
I0204 16:15:24.408566  8495 net.cpp:241] data_data_0_split does not need backward computation.
I0204 16:15:24.408577  8495 net.cpp:241] data does not need backward computation.
I0204 16:15:24.408581  8495 net.cpp:284] This network produces output accuracy
I0204 16:15:24.408584  8495 net.cpp:284] This network produces output loss
I0204 16:15:24.408597  8495 net.cpp:298] Network initialization done.
I0204 16:15:24.408601  8495 net.cpp:299] Memory required for data: 36695976
I0204 16:15:24.408661  8495 solver.cpp:65] Solver scaffolding done.
I0204 16:15:24.408686  8495 caffe.cpp:211] Starting Optimization
I0204 16:15:24.408691  8495 solver.cpp:293] Solving FCN
I0204 16:15:24.408694  8495 solver.cpp:294] Learning Rate Policy: multistep
I0204 16:15:24.409342  8495 solver.cpp:346] Iteration 0, Testing net (#0)
I0204 16:15:24.904726  8495 solver.cpp:414]     Test net output #0: accuracy = 0.0147312
I0204 16:15:24.904774  8495 solver.cpp:414]     Test net output #1: loss = 0.693147 (* 1 = 0.693147 loss)
I0204 16:15:24.918745  8495 solver.cpp:242] Iteration 0, loss = 0.693147
I0204 16:15:24.918788  8495 solver.cpp:258]     Train net output #0: loss = 0.693147 (* 1 = 0.693147 loss)
I0204 16:15:24.918812  8495 solver.cpp:571] Iteration 0, lr = 0.01
I0204 16:15:29.352445  8495 solver.cpp:346] Iteration 200, Testing net (#0)
I0204 16:15:29.846392  8495 solver.cpp:414]     Test net output #0: accuracy = 0.985269
I0204 16:15:29.846441  8495 solver.cpp:414]     Test net output #1: loss = 0.0777838 (* 1 = 0.0777838 loss)
I0204 16:15:29.855865  8495 solver.cpp:242] Iteration 200, loss = 0.125886
I0204 16:15:29.855890  8495 solver.cpp:258]     Train net output #0: loss = 0.0514527 (* 1 = 0.0514527 loss)
I0204 16:15:29.855897  8495 solver.cpp:571] Iteration 200, lr = 0.01
I0204 16:15:34.286579  8495 solver.cpp:346] Iteration 400, Testing net (#0)
I0204 16:15:34.784437  8495 solver.cpp:414]     Test net output #0: accuracy = 0.985269
I0204 16:15:34.784487  8495 solver.cpp:414]     Test net output #1: loss = 0.0770106 (* 1 = 0.0770106 loss)
I0204 16:15:34.794013  8495 solver.cpp:242] Iteration 400, loss = 0.0850029
I0204 16:15:34.794039  8495 solver.cpp:258]     Train net output #0: loss = 0.0399844 (* 1 = 0.0399844 loss)
I0204 16:15:34.794046  8495 solver.cpp:571] Iteration 400, lr = 0.01
I0204 16:15:39.225090  8495 solver.cpp:346] Iteration 600, Testing net (#0)
I0204 16:15:39.720185  8495 solver.cpp:414]     Test net output #0: accuracy = 0.985269
I0204 16:15:39.720232  8495 solver.cpp:414]     Test net output #1: loss = 0.0768948 (* 1 = 0.0768948 loss)
I0204 16:15:39.729756  8495 solver.cpp:242] Iteration 600, loss = 0.0837906
I0204 16:15:39.729785  8495 solver.cpp:258]     Train net output #0: loss = 0.111128 (* 1 = 0.111128 loss)
I0204 16:15:39.729794  8495 solver.cpp:571] Iteration 600, lr = 0.01
I0204 16:15:44.160367  8495 solver.cpp:346] Iteration 800, Testing net (#0)
I0204 16:15:44.656721  8495 solver.cpp:414]     Test net output #0: accuracy = 0.985269
I0204 16:15:44.656762  8495 solver.cpp:414]     Test net output #1: loss = 0.0769211 (* 1 = 0.0769211 loss)
I0204 16:15:44.666132  8495 solver.cpp:242] Iteration 800, loss = 0.0855313
I0204 16:15:44.666157  8495 solver.cpp:258]     Train net output #0: loss = 0.158326 (* 1 = 0.158326 loss)
I0204 16:15:44.666165  8495 solver.cpp:571] Iteration 800, lr = 0.01
I0204 16:15:49.101770  8495 solver.cpp:346] Iteration 1000, Testing net (#0)
I0204 16:15:49.599789  8495 solver.cpp:414]     Test net output #0: accuracy = 0.985269
I0204 16:15:49.599838  8495 solver.cpp:414]     Test net output #1: loss = 0.0768645 (* 1 = 0.0768645 loss)
I0204 16:15:49.609256  8495 solver.cpp:242] Iteration 1000, loss = 0.084219
I0204 16:15:49.609280  8495 solver.cpp:258]     Train net output #0: loss = 0.0453213 (* 1 = 0.0453213 loss)
I0204 16:15:49.609288  8495 solver.cpp:571] Iteration 1000, lr = 0.01
I0204 16:15:54.051951  8495 solver.cpp:346] Iteration 1200, Testing net (#0)
I0204 16:15:54.545891  8495 solver.cpp:414]     Test net output #0: accuracy = 0.985269
I0204 16:15:54.545938  8495 solver.cpp:414]     Test net output #1: loss = 0.0768287 (* 1 = 0.0768287 loss)
I0204 16:15:54.554811  8495 solver.cpp:242] Iteration 1200, loss = 0.08285
I0204 16:15:54.554852  8495 solver.cpp:258]     Train net output #0: loss = 0.054202 (* 1 = 0.054202 loss)
I0204 16:15:54.554860  8495 solver.cpp:571] Iteration 1200, lr = 0.01
I0204 16:15:58.990219  8495 solver.cpp:346] Iteration 1400, Testing net (#0)
I0204 16:15:59.487946  8495 solver.cpp:414]     Test net output #0: accuracy = 0.985269
I0204 16:15:59.487993  8495 solver.cpp:414]     Test net output #1: loss = 0.0768561 (* 1 = 0.0768561 loss)
I0204 16:15:59.497516  8495 solver.cpp:242] Iteration 1400, loss = 0.0860473
I0204 16:15:59.497581  8495 solver.cpp:258]     Train net output #0: loss = 0.0475886 (* 1 = 0.0475886 loss)
I0204 16:15:59.497597  8495 solver.cpp:571] Iteration 1400, lr = 0.01
I0204 16:16:03.930333  8495 solver.cpp:346] Iteration 1600, Testing net (#0)
I0204 16:16:04.423868  8495 solver.cpp:414]     Test net output #0: accuracy = 0.985269
I0204 16:16:04.423909  8495 solver.cpp:414]     Test net output #1: loss = 0.0768864 (* 1 = 0.0768864 loss)
I0204 16:16:04.433326  8495 solver.cpp:242] Iteration 1600, loss = 0.0856128
I0204 16:16:04.433357  8495 solver.cpp:258]     Train net output #0: loss = 0.0695341 (* 1 = 0.0695341 loss)
I0204 16:16:04.433364  8495 solver.cpp:571] Iteration 1600, lr = 0.01
I0204 16:16:08.893319  8495 solver.cpp:346] Iteration 1800, Testing net (#0)
I0204 16:16:09.399235  8495 solver.cpp:414]     Test net output #0: accuracy = 0.985269
I0204 16:16:09.399312  8495 solver.cpp:414]     Test net output #1: loss = 0.0768765 (* 1 = 0.0768765 loss)
I0204 16:16:09.409395  8495 solver.cpp:242] Iteration 1800, loss = 0.085039
I0204 16:16:09.409435  8495 solver.cpp:258]     Train net output #0: loss = 0.139454 (* 1 = 0.139454 loss)
I0204 16:16:09.409445  8495 solver.cpp:571] Iteration 1800, lr = 0.01
I0204 16:16:14.021071  8495 solver.cpp:346] Iteration 2000, Testing net (#0)
I0204 16:16:14.514355  8495 solver.cpp:414]     Test net output #0: accuracy = 0.985269
I0204 16:16:14.514405  8495 solver.cpp:414]     Test net output #1: loss = 0.0768714 (* 1 = 0.0768714 loss)
I0204 16:16:14.523962  8495 solver.cpp:242] Iteration 2000, loss = 0.0836403
I0204 16:16:14.523994  8495 solver.cpp:258]     Train net output #0: loss = 0.119882 (* 1 = 0.119882 loss)
I0204 16:16:14.524003  8495 solver.cpp:571] Iteration 2000, lr = 0.01
I0204 16:16:18.962191  8495 solver.cpp:346] Iteration 2200, Testing net (#0)
I0204 16:16:19.456560  8495 solver.cpp:414]     Test net output #0: accuracy = 0.985269
I0204 16:16:19.456609  8495 solver.cpp:414]     Test net output #1: loss = 0.0769167 (* 1 = 0.0769167 loss)
I0204 16:16:19.466099  8495 solver.cpp:242] Iteration 2200, loss = 0.0860142
I0204 16:16:19.466123  8495 solver.cpp:258]     Train net output #0: loss = 0.0827667 (* 1 = 0.0827667 loss)
I0204 16:16:19.466131  8495 solver.cpp:571] Iteration 2200, lr = 0.01
I0204 16:16:23.899327  8495 solver.cpp:346] Iteration 2400, Testing net (#0)
I0204 16:16:24.395963  8495 solver.cpp:414]     Test net output #0: accuracy = 0.985269
I0204 16:16:24.396052  8495 solver.cpp:414]     Test net output #1: loss = 0.0768467 (* 1 = 0.0768467 loss)
I0204 16:16:24.405505  8495 solver.cpp:242] Iteration 2400, loss = 0.08356
I0204 16:16:24.405530  8495 solver.cpp:258]     Train net output #0: loss = 0.084374 (* 1 = 0.084374 loss)
I0204 16:16:24.405539  8495 solver.cpp:571] Iteration 2400, lr = 0.01
I0204 16:16:26.659384  8495 solver.cpp:449] Snapshotting to binary proto file ./model_logs/fcn_iter_2500.caffemodel
I0204 16:16:26.695137  8495 solver.cpp:734] Snapshotting solver state to binary proto file./model_logs/fcn_iter_2500.solverstate
I0204 16:16:28.956763  8495 solver.cpp:346] Iteration 2600, Testing net (#0)
I0204 16:16:29.450177  8495 solver.cpp:414]     Test net output #0: accuracy = 0.985269
I0204 16:16:29.450225  8495 solver.cpp:414]     Test net output #1: loss = 0.0768229 (* 1 = 0.0768229 loss)
I0204 16:16:29.459789  8495 solver.cpp:242] Iteration 2600, loss = 0.0836864
I0204 16:16:29.459830  8495 solver.cpp:258]     Train net output #0: loss = 0.0505157 (* 1 = 0.0505157 loss)
I0204 16:16:29.459854  8495 solver.cpp:571] Iteration 2600, lr = 0.01
I0204 16:16:33.926933  8495 solver.cpp:346] Iteration 2800, Testing net (#0)
I0204 16:16:34.421846  8495 solver.cpp:414]     Test net output #0: accuracy = 0.985269
I0204 16:16:34.421895  8495 solver.cpp:414]     Test net output #1: loss = 0.0768516 (* 1 = 0.0768516 loss)
I0204 16:16:34.431299  8495 solver.cpp:242] Iteration 2800, loss = 0.0852106
I0204 16:16:34.431323  8495 solver.cpp:258]     Train net output #0: loss = 0.124794 (* 1 = 0.124794 loss)
I0204 16:16:34.431329  8495 solver.cpp:571] Iteration 2800, lr = 0.01
I0204 16:16:38.991662  8495 solver.cpp:346] Iteration 3000, Testing net (#0)
I0204 16:16:39.490504  8495 solver.cpp:414]     Test net output #0: accuracy = 0.985269
I0204 16:16:39.490586  8495 solver.cpp:414]     Test net output #1: loss = 0.076881 (* 1 = 0.076881 loss)
I0204 16:16:39.499841  8495 solver.cpp:242] Iteration 3000, loss = 0.0855414
I0204 16:16:39.499871  8495 solver.cpp:258]     Train net output #0: loss = 0.0508568 (* 1 = 0.0508568 loss)
I0204 16:16:39.499879  8495 solver.cpp:571] Iteration 3000, lr = 0.01
I0204 16:16:43.934546  8495 solver.cpp:346] Iteration 3200, Testing net (#0)
I0204 16:16:44.435899  8495 solver.cpp:414]     Test net output #0: accuracy = 0.985269
I0204 16:16:44.435946  8495 solver.cpp:414]     Test net output #1: loss = 0.0768601 (* 1 = 0.0768601 loss)
I0204 16:16:44.445555  8495 solver.cpp:242] Iteration 3200, loss = 0.0842963
I0204 16:16:44.445588  8495 solver.cpp:258]     Train net output #0: loss = 0.0443754 (* 1 = 0.0443754 loss)
I0204 16:16:44.445596  8495 solver.cpp:571] Iteration 3200, lr = 0.01
I0204 16:16:48.959622  8495 solver.cpp:346] Iteration 3400, Testing net (#0)
I0204 16:16:49.454259  8495 solver.cpp:414]     Test net output #0: accuracy = 0.985269
I0204 16:16:49.454311  8495 solver.cpp:414]     Test net output #1: loss = 0.0768581 (* 1 = 0.0768581 loss)
I0204 16:16:49.463726  8495 solver.cpp:242] Iteration 3400, loss = 0.0847801
I0204 16:16:49.463768  8495 solver.cpp:258]     Train net output #0: loss = 0.0859757 (* 1 = 0.0859757 loss)
I0204 16:16:49.463776  8495 solver.cpp:571] Iteration 3400, lr = 0.01
I0204 16:16:53.899371  8495 solver.cpp:346] Iteration 3600, Testing net (#0)
I0204 16:16:54.395613  8495 solver.cpp:414]     Test net output #0: accuracy = 0.985269
I0204 16:16:54.395661  8495 solver.cpp:414]     Test net output #1: loss = 0.0768876 (* 1 = 0.0768876 loss)
I0204 16:16:54.405200  8495 solver.cpp:242] Iteration 3600, loss = 0.0858713
I0204 16:16:54.405335  8495 solver.cpp:258]     Train net output #0: loss = 0.0440177 (* 1 = 0.0440177 loss)
I0204 16:16:54.405344  8495 solver.cpp:571] Iteration 3600, lr = 0.01
I0204 16:16:58.890519  8495 solver.cpp:346] Iteration 3800, Testing net (#0)
I0204 16:16:59.402531  8495 solver.cpp:414]     Test net output #0: accuracy = 0.985269
I0204 16:16:59.402580  8495 solver.cpp:414]     Test net output #1: loss = 0.0767998 (* 1 = 0.0767998 loss)
I0204 16:16:59.412204  8495 solver.cpp:242] Iteration 3800, loss = 0.08314
I0204 16:16:59.412230  8495 solver.cpp:258]     Train net output #0: loss = 0.0855861 (* 1 = 0.0855861 loss)
I0204 16:16:59.412238  8495 solver.cpp:571] Iteration 3800, lr = 0.01
I0204 16:17:03.942956  8495 solver.cpp:346] Iteration 4000, Testing net (#0)
I0204 16:17:04.436254  8495 solver.cpp:414]     Test net output #0: accuracy = 0.985269
I0204 16:17:04.436303  8495 solver.cpp:414]     Test net output #1: loss = 0.0767555 (* 1 = 0.0767555 loss)
I0204 16:17:04.446168  8495 solver.cpp:242] Iteration 4000, loss = 0.0839944
I0204 16:17:04.446199  8495 solver.cpp:258]     Train net output #0: loss = 0.081654 (* 1 = 0.081654 loss)
I0204 16:17:04.446208  8495 solver.cpp:571] Iteration 4000, lr = 0.01
I0204 16:17:08.858680  8495 solver.cpp:346] Iteration 4200, Testing net (#0)
I0204 16:17:09.340323  8495 solver.cpp:414]     Test net output #0: accuracy = 0.985269
I0204 16:17:09.340383  8495 solver.cpp:414]     Test net output #1: loss = 0.0767372 (* 1 = 0.0767372 loss)
I0204 16:17:09.349814  8495 solver.cpp:242] Iteration 4200, loss = 0.0852962
I0204 16:17:09.349838  8495 solver.cpp:258]     Train net output #0: loss = 0.0890459 (* 1 = 0.0890459 loss)
I0204 16:17:09.349846  8495 solver.cpp:571] Iteration 4200, lr = 0.01
I0204 16:17:13.753310  8495 solver.cpp:346] Iteration 4400, Testing net (#0)
I0204 16:17:14.235540  8495 solver.cpp:414]     Test net output #0: accuracy = 0.985269
I0204 16:17:14.235587  8495 solver.cpp:414]     Test net output #1: loss = 0.0765339 (* 1 = 0.0765339 loss)
I0204 16:17:14.245141  8495 solver.cpp:242] Iteration 4400, loss = 0.0853301
I0204 16:17:14.245165  8495 solver.cpp:258]     Train net output #0: loss = 0.0645692 (* 1 = 0.0645692 loss)
I0204 16:17:14.245172  8495 solver.cpp:571] Iteration 4400, lr = 0.01
I0204 16:17:18.658149  8495 solver.cpp:346] Iteration 4600, Testing net (#0)
I0204 16:17:19.141257  8495 solver.cpp:414]     Test net output #0: accuracy = 0.985269
I0204 16:17:19.141317  8495 solver.cpp:414]     Test net output #1: loss = 0.0735844 (* 1 = 0.0735844 loss)
I0204 16:17:19.150239  8495 solver.cpp:242] Iteration 4600, loss = 0.0828967
I0204 16:17:19.150264  8495 solver.cpp:258]     Train net output #0: loss = 0.136602 (* 1 = 0.136602 loss)
I0204 16:17:19.150270  8495 solver.cpp:571] Iteration 4600, lr = 0.01
I0204 16:17:23.561218  8495 solver.cpp:346] Iteration 4800, Testing net (#0)
I0204 16:17:24.043148  8495 solver.cpp:414]     Test net output #0: accuracy = 0.985269
I0204 16:17:24.043195  8495 solver.cpp:414]     Test net output #1: loss = 0.0716435 (* 1 = 0.0716435 loss)
I0204 16:17:24.052577  8495 solver.cpp:242] Iteration 4800, loss = 0.0775257
I0204 16:17:24.052600  8495 solver.cpp:258]     Train net output #0: loss = 0.0415835 (* 1 = 0.0415835 loss)
I0204 16:17:24.052608  8495 solver.cpp:571] Iteration 4800, lr = 0.01
I0204 16:17:28.457356  8495 solver.cpp:449] Snapshotting to binary proto file ./model_logs/fcn_iter_5000.caffemodel
I0204 16:17:28.491725  8495 solver.cpp:734] Snapshotting solver state to binary proto file./model_logs/fcn_iter_5000.solverstate
I0204 16:17:28.499408  8495 solver.cpp:346] Iteration 5000, Testing net (#0)
I0204 16:17:28.971247  8495 solver.cpp:414]     Test net output #0: accuracy = 0.98527
I0204 16:17:28.971293  8495 solver.cpp:414]     Test net output #1: loss = 0.0561781 (* 1 = 0.0561781 loss)
I0204 16:17:28.980147  8495 solver.cpp:242] Iteration 5000, loss = 0.0687003
I0204 16:17:28.980170  8495 solver.cpp:258]     Train net output #0: loss = 0.0978786 (* 1 = 0.0978786 loss)
I0204 16:17:28.980178  8495 solver.cpp:571] Iteration 5000, lr = 0.01
I0204 16:17:33.385006  8495 solver.cpp:346] Iteration 5200, Testing net (#0)
I0204 16:17:33.867548  8495 solver.cpp:414]     Test net output #0: accuracy = 0.985589
I0204 16:17:33.867605  8495 solver.cpp:414]     Test net output #1: loss = 0.0479394 (* 1 = 0.0479394 loss)
I0204 16:17:33.876981  8495 solver.cpp:242] Iteration 5200, loss = 0.0474165
I0204 16:17:33.877003  8495 solver.cpp:258]     Train net output #0: loss = 0.0438728 (* 1 = 0.0438728 loss)
I0204 16:17:33.877010  8495 solver.cpp:571] Iteration 5200, lr = 0.01
I0204 16:17:38.283327  8495 solver.cpp:346] Iteration 5400, Testing net (#0)
I0204 16:17:38.765967  8495 solver.cpp:414]     Test net output #0: accuracy = 0.987331
I0204 16:17:38.766016  8495 solver.cpp:414]     Test net output #1: loss = 0.0381556 (* 1 = 0.0381556 loss)
I0204 16:17:38.775241  8495 solver.cpp:242] Iteration 5400, loss = 0.0397121
I0204 16:17:38.775264  8495 solver.cpp:258]     Train net output #0: loss = 0.0554243 (* 1 = 0.0554243 loss)
I0204 16:17:38.775272  8495 solver.cpp:571] Iteration 5400, lr = 0.01
I0204 16:17:43.179060  8495 solver.cpp:346] Iteration 5600, Testing net (#0)
I0204 16:17:43.661077  8495 solver.cpp:414]     Test net output #0: accuracy = 0.987263
I0204 16:17:43.661123  8495 solver.cpp:414]     Test net output #1: loss = 0.0402286 (* 1 = 0.0402286 loss)
I0204 16:17:43.670238  8495 solver.cpp:242] Iteration 5600, loss = 0.0320132
I0204 16:17:43.670264  8495 solver.cpp:258]     Train net output #0: loss = 0.0370185 (* 1 = 0.0370185 loss)
I0204 16:17:43.670277  8495 solver.cpp:571] Iteration 5600, lr = 0.01
I0204 16:17:48.076051  8495 solver.cpp:346] Iteration 5800, Testing net (#0)
I0204 16:17:48.559494  8495 solver.cpp:414]     Test net output #0: accuracy = 0.99
I0204 16:17:48.559540  8495 solver.cpp:414]     Test net output #1: loss = 0.025851 (* 1 = 0.025851 loss)
I0204 16:17:48.568415  8495 solver.cpp:242] Iteration 5800, loss = 0.0264042
I0204 16:17:48.568444  8495 solver.cpp:258]     Train net output #0: loss = 0.0158274 (* 1 = 0.0158274 loss)
I0204 16:17:48.568451  8495 solver.cpp:571] Iteration 5800, lr = 0.01
I0204 16:17:52.973346  8495 solver.cpp:346] Iteration 6000, Testing net (#0)
I0204 16:17:53.454996  8495 solver.cpp:414]     Test net output #0: accuracy = 0.991576
I0204 16:17:53.455044  8495 solver.cpp:414]     Test net output #1: loss = 0.0230127 (* 1 = 0.0230127 loss)
I0204 16:17:53.464246  8495 solver.cpp:242] Iteration 6000, loss = 0.0212286
I0204 16:17:53.464270  8495 solver.cpp:258]     Train net output #0: loss = 0.0130624 (* 1 = 0.0130624 loss)
I0204 16:17:53.464277  8495 solver.cpp:571] Iteration 6000, lr = 0.01
I0204 16:17:57.867622  8495 solver.cpp:346] Iteration 6200, Testing net (#0)
I0204 16:17:58.348953  8495 solver.cpp:414]     Test net output #0: accuracy = 0.990983
I0204 16:17:58.349000  8495 solver.cpp:414]     Test net output #1: loss = 0.0233913 (* 1 = 0.0233913 loss)
I0204 16:17:58.358382  8495 solver.cpp:242] Iteration 6200, loss = 0.0178222
I0204 16:17:58.358415  8495 solver.cpp:258]     Train net output #0: loss = 0.0126093 (* 1 = 0.0126093 loss)
I0204 16:17:58.358422  8495 solver.cpp:571] Iteration 6200, lr = 0.01
I0204 16:18:02.764114  8495 solver.cpp:346] Iteration 6400, Testing net (#0)
I0204 16:18:03.247948  8495 solver.cpp:414]     Test net output #0: accuracy = 0.993253
I0204 16:18:03.248008  8495 solver.cpp:414]     Test net output #1: loss = 0.0169781 (* 1 = 0.0169781 loss)
I0204 16:18:03.257252  8495 solver.cpp:242] Iteration 6400, loss = 0.0152701
I0204 16:18:03.257278  8495 solver.cpp:258]     Train net output #0: loss = 0.0102587 (* 1 = 0.0102587 loss)
I0204 16:18:03.257287  8495 solver.cpp:571] Iteration 6400, lr = 0.01
I0204 16:18:07.657577  8495 solver.cpp:346] Iteration 6600, Testing net (#0)
I0204 16:18:08.139446  8495 solver.cpp:414]     Test net output #0: accuracy = 0.993181
I0204 16:18:08.139492  8495 solver.cpp:414]     Test net output #1: loss = 0.0166207 (* 1 = 0.0166207 loss)
I0204 16:18:08.148850  8495 solver.cpp:242] Iteration 6600, loss = 0.0136947
I0204 16:18:08.148874  8495 solver.cpp:258]     Train net output #0: loss = 0.00727274 (* 1 = 0.00727274 loss)
I0204 16:18:08.148880  8495 solver.cpp:571] Iteration 6600, lr = 0.01
I0204 16:18:12.550051  8495 solver.cpp:346] Iteration 6800, Testing net (#0)
I0204 16:18:13.032096  8495 solver.cpp:414]     Test net output #0: accuracy = 0.991665
I0204 16:18:13.032143  8495 solver.cpp:414]     Test net output #1: loss = 0.0223651 (* 1 = 0.0223651 loss)
I0204 16:18:13.041612  8495 solver.cpp:242] Iteration 6800, loss = 0.0116347
I0204 16:18:13.041635  8495 solver.cpp:258]     Train net output #0: loss = 0.0194683 (* 1 = 0.0194683 loss)
I0204 16:18:13.041642  8495 solver.cpp:571] Iteration 6800, lr = 0.01
I0204 16:18:17.452199  8495 solver.cpp:346] Iteration 7000, Testing net (#0)
I0204 16:18:17.934837  8495 solver.cpp:414]     Test net output #0: accuracy = 0.9946
I0204 16:18:17.934897  8495 solver.cpp:414]     Test net output #1: loss = 0.0139796 (* 1 = 0.0139796 loss)
I0204 16:18:17.944653  8495 solver.cpp:242] Iteration 7000, loss = 0.0110648
I0204 16:18:17.944677  8495 solver.cpp:258]     Train net output #0: loss = 0.00989245 (* 1 = 0.00989245 loss)
I0204 16:18:17.944684  8495 solver.cpp:571] Iteration 7000, lr = 0.01
I0204 16:18:22.346828  8495 solver.cpp:346] Iteration 7200, Testing net (#0)
I0204 16:18:22.828699  8495 solver.cpp:414]     Test net output #0: accuracy = 0.993256
I0204 16:18:22.828748  8495 solver.cpp:414]     Test net output #1: loss = 0.0188972 (* 1 = 0.0188972 loss)
I0204 16:18:22.838141  8495 solver.cpp:242] Iteration 7200, loss = 0.0100572
I0204 16:18:22.838165  8495 solver.cpp:258]     Train net output #0: loss = 0.0135837 (* 1 = 0.0135837 loss)
I0204 16:18:22.838173  8495 solver.cpp:571] Iteration 7200, lr = 0.01
I0204 16:18:27.240454  8495 solver.cpp:346] Iteration 7400, Testing net (#0)
I0204 16:18:27.722309  8495 solver.cpp:414]     Test net output #0: accuracy = 0.994228
I0204 16:18:27.722357  8495 solver.cpp:414]     Test net output #1: loss = 0.0154105 (* 1 = 0.0154105 loss)
I0204 16:18:27.731582  8495 solver.cpp:242] Iteration 7400, loss = 0.0092117
I0204 16:18:27.731606  8495 solver.cpp:258]     Train net output #0: loss = 0.0230724 (* 1 = 0.0230724 loss)
I0204 16:18:27.731612  8495 solver.cpp:571] Iteration 7400, lr = 0.01
I0204 16:18:29.926597  8495 solver.cpp:449] Snapshotting to binary proto file ./model_logs/fcn_iter_7500.caffemodel
I0204 16:18:29.957113  8495 solver.cpp:734] Snapshotting solver state to binary proto file./model_logs/fcn_iter_7500.solverstate
I0204 16:18:32.165947  8495 solver.cpp:346] Iteration 7600, Testing net (#0)
I0204 16:18:32.647905  8495 solver.cpp:414]     Test net output #0: accuracy = 0.99503
I0204 16:18:32.647951  8495 solver.cpp:414]     Test net output #1: loss = 0.0122734 (* 1 = 0.0122734 loss)
I0204 16:18:32.657135  8495 solver.cpp:242] Iteration 7600, loss = 0.00910907
I0204 16:18:32.657157  8495 solver.cpp:258]     Train net output #0: loss = 0.00849335 (* 1 = 0.00849335 loss)
I0204 16:18:32.657166  8495 solver.cpp:571] Iteration 7600, lr = 0.01
I0204 16:18:37.059737  8495 solver.cpp:346] Iteration 7800, Testing net (#0)
I0204 16:18:37.542382  8495 solver.cpp:414]     Test net output #0: accuracy = 0.995373
I0204 16:18:37.542428  8495 solver.cpp:414]     Test net output #1: loss = 0.0114992 (* 1 = 0.0114992 loss)
I0204 16:18:37.551645  8495 solver.cpp:242] Iteration 7800, loss = 0.00856641
I0204 16:18:37.551668  8495 solver.cpp:258]     Train net output #0: loss = 0.00860334 (* 1 = 0.00860334 loss)
I0204 16:18:37.551676  8495 solver.cpp:571] Iteration 7800, lr = 0.01
I0204 16:18:41.955147  8495 solver.cpp:346] Iteration 8000, Testing net (#0)
I0204 16:18:42.439363  8495 solver.cpp:414]     Test net output #0: accuracy = 0.994985
I0204 16:18:42.439411  8495 solver.cpp:414]     Test net output #1: loss = 0.0128792 (* 1 = 0.0128792 loss)
I0204 16:18:42.448567  8495 solver.cpp:242] Iteration 8000, loss = 0.00816118
I0204 16:18:42.448591  8495 solver.cpp:258]     Train net output #0: loss = 0.0080915 (* 1 = 0.0080915 loss)
I0204 16:18:42.448599  8495 solver.cpp:571] Iteration 8000, lr = 0.01
I0204 16:18:46.851507  8495 solver.cpp:346] Iteration 8200, Testing net (#0)
I0204 16:18:47.334717  8495 solver.cpp:414]     Test net output #0: accuracy = 0.99593
I0204 16:18:47.334777  8495 solver.cpp:414]     Test net output #1: loss = 0.0104521 (* 1 = 0.0104521 loss)
I0204 16:18:47.343870  8495 solver.cpp:242] Iteration 8200, loss = 0.00770003
I0204 16:18:47.343894  8495 solver.cpp:258]     Train net output #0: loss = 0.0143184 (* 1 = 0.0143184 loss)
I0204 16:18:47.343902  8495 solver.cpp:571] Iteration 8200, lr = 0.01
I0204 16:18:51.742841  8495 solver.cpp:346] Iteration 8400, Testing net (#0)
I0204 16:18:52.225359  8495 solver.cpp:414]     Test net output #0: accuracy = 0.996535
I0204 16:18:52.225406  8495 solver.cpp:414]     Test net output #1: loss = 0.0088326 (* 1 = 0.0088326 loss)
I0204 16:18:52.234428  8495 solver.cpp:242] Iteration 8400, loss = 0.00730181
I0204 16:18:52.234455  8495 solver.cpp:258]     Train net output #0: loss = 0.00444089 (* 1 = 0.00444089 loss)
I0204 16:18:52.234462  8495 solver.cpp:571] Iteration 8400, lr = 0.01
I0204 16:18:56.639529  8495 solver.cpp:346] Iteration 8600, Testing net (#0)
I0204 16:18:57.120707  8495 solver.cpp:414]     Test net output #0: accuracy = 0.996223
I0204 16:18:57.120755  8495 solver.cpp:414]     Test net output #1: loss = 0.009651 (* 1 = 0.009651 loss)
I0204 16:18:57.130014  8495 solver.cpp:242] Iteration 8600, loss = 0.00665596
I0204 16:18:57.130043  8495 solver.cpp:258]     Train net output #0: loss = 0.00714278 (* 1 = 0.00714278 loss)
I0204 16:18:57.130061  8495 solver.cpp:571] Iteration 8600, lr = 0.01
I0204 16:19:01.533674  8495 solver.cpp:346] Iteration 8800, Testing net (#0)
I0204 16:19:02.015506  8495 solver.cpp:414]     Test net output #0: accuracy = 0.995986
I0204 16:19:02.015553  8495 solver.cpp:414]     Test net output #1: loss = 0.00988569 (* 1 = 0.00988569 loss)
I0204 16:19:02.024888  8495 solver.cpp:242] Iteration 8800, loss = 0.0062932
I0204 16:19:02.024911  8495 solver.cpp:258]     Train net output #0: loss = 0.00590142 (* 1 = 0.00590142 loss)
I0204 16:19:02.024919  8495 solver.cpp:571] Iteration 8800, lr = 0.01
I0204 16:19:06.425839  8495 solver.cpp:346] Iteration 9000, Testing net (#0)
I0204 16:19:06.906800  8495 solver.cpp:414]     Test net output #0: accuracy = 0.996415
I0204 16:19:06.906859  8495 solver.cpp:414]     Test net output #1: loss = 0.00873783 (* 1 = 0.00873783 loss)
I0204 16:19:06.916121  8495 solver.cpp:242] Iteration 9000, loss = 0.0060551
I0204 16:19:06.916146  8495 solver.cpp:258]     Train net output #0: loss = 0.00811896 (* 1 = 0.00811896 loss)
I0204 16:19:06.916154  8495 solver.cpp:571] Iteration 9000, lr = 0.01
I0204 16:19:11.327675  8495 solver.cpp:346] Iteration 9200, Testing net (#0)
I0204 16:19:11.810175  8495 solver.cpp:414]     Test net output #0: accuracy = 0.996294
I0204 16:19:11.810222  8495 solver.cpp:414]     Test net output #1: loss = 0.00935785 (* 1 = 0.00935785 loss)
I0204 16:19:11.819380  8495 solver.cpp:242] Iteration 9200, loss = 0.0057129
I0204 16:19:11.819403  8495 solver.cpp:258]     Train net output #0: loss = 0.0046052 (* 1 = 0.0046052 loss)
I0204 16:19:11.819411  8495 solver.cpp:571] Iteration 9200, lr = 0.01
I0204 16:19:16.232163  8495 solver.cpp:346] Iteration 9400, Testing net (#0)
I0204 16:19:16.713419  8495 solver.cpp:414]     Test net output #0: accuracy = 0.996265
I0204 16:19:16.713469  8495 solver.cpp:414]     Test net output #1: loss = 0.00957476 (* 1 = 0.00957476 loss)
I0204 16:19:16.722431  8495 solver.cpp:242] Iteration 9400, loss = 0.005352
I0204 16:19:16.722455  8495 solver.cpp:258]     Train net output #0: loss = 0.00311988 (* 1 = 0.00311988 loss)
I0204 16:19:16.722461  8495 solver.cpp:571] Iteration 9400, lr = 0.01
I0204 16:19:21.127636  8495 solver.cpp:346] Iteration 9600, Testing net (#0)
I0204 16:19:21.609285  8495 solver.cpp:414]     Test net output #0: accuracy = 0.996971
I0204 16:19:21.609333  8495 solver.cpp:414]     Test net output #1: loss = 0.00764994 (* 1 = 0.00764994 loss)
I0204 16:19:21.618276  8495 solver.cpp:242] Iteration 9600, loss = 0.00511897
I0204 16:19:21.618300  8495 solver.cpp:258]     Train net output #0: loss = 0.00672081 (* 1 = 0.00672081 loss)
I0204 16:19:21.618307  8495 solver.cpp:571] Iteration 9600, lr = 0.01
I0204 16:19:26.054023  8495 solver.cpp:346] Iteration 9800, Testing net (#0)
I0204 16:19:26.549212  8495 solver.cpp:414]     Test net output #0: accuracy = 0.996576
I0204 16:19:26.549260  8495 solver.cpp:414]     Test net output #1: loss = 0.00839528 (* 1 = 0.00839528 loss)
I0204 16:19:26.558832  8495 solver.cpp:242] Iteration 9800, loss = 0.00508706
I0204 16:19:26.558858  8495 solver.cpp:258]     Train net output #0: loss = 0.00545029 (* 1 = 0.00545029 loss)
I0204 16:19:26.558866  8495 solver.cpp:571] Iteration 9800, lr = 0.01
I0204 16:19:31.010166  8495 solver.cpp:449] Snapshotting to binary proto file ./model_logs/fcn_iter_10000.caffemodel
I0204 16:19:31.041743  8495 solver.cpp:734] Snapshotting solver state to binary proto file./model_logs/fcn_iter_10000.solverstate
I0204 16:19:31.049767  8495 solver.cpp:346] Iteration 10000, Testing net (#0)
I0204 16:19:31.536875  8495 solver.cpp:414]     Test net output #0: accuracy = 0.996483
I0204 16:19:31.536926  8495 solver.cpp:414]     Test net output #1: loss = 0.00895416 (* 1 = 0.00895416 loss)
I0204 16:19:31.546532  8495 solver.cpp:242] Iteration 10000, loss = 0.00493823
I0204 16:19:31.546566  8495 solver.cpp:258]     Train net output #0: loss = 0.00655926 (* 1 = 0.00655926 loss)
I0204 16:19:31.546574  8495 solver.cpp:511] MultiStep Status: Iteration 10000, step = 1
I0204 16:19:31.546591  8495 solver.cpp:571] Iteration 10000, lr = 0.001
I0204 16:19:35.999752  8495 solver.cpp:346] Iteration 10200, Testing net (#0)
I0204 16:19:36.496139  8495 solver.cpp:414]     Test net output #0: accuracy = 0.996667
I0204 16:19:36.496186  8495 solver.cpp:414]     Test net output #1: loss = 0.00819178 (* 1 = 0.00819178 loss)
I0204 16:19:36.505811  8495 solver.cpp:242] Iteration 10200, loss = 0.00562589
I0204 16:19:36.505842  8495 solver.cpp:258]     Train net output #0: loss = 0.00609664 (* 1 = 0.00609664 loss)
I0204 16:19:36.505849  8495 solver.cpp:571] Iteration 10200, lr = 0.001
I0204 16:19:40.963793  8495 solver.cpp:346] Iteration 10400, Testing net (#0)
I0204 16:19:41.458961  8495 solver.cpp:414]     Test net output #0: accuracy = 0.99682
I0204 16:19:41.459048  8495 solver.cpp:414]     Test net output #1: loss = 0.00766195 (* 1 = 0.00766195 loss)
I0204 16:19:41.468433  8495 solver.cpp:242] Iteration 10400, loss = 0.00489193
I0204 16:19:41.468462  8495 solver.cpp:258]     Train net output #0: loss = 0.00537521 (* 1 = 0.00537521 loss)
I0204 16:19:41.468469  8495 solver.cpp:571] Iteration 10400, lr = 0.001
I0204 16:19:45.915352  8495 solver.cpp:346] Iteration 10600, Testing net (#0)
I0204 16:19:46.410218  8495 solver.cpp:414]     Test net output #0: accuracy = 0.99694
I0204 16:19:46.410266  8495 solver.cpp:414]     Test net output #1: loss = 0.00751248 (* 1 = 0.00751248 loss)
I0204 16:19:46.419852  8495 solver.cpp:242] Iteration 10600, loss = 0.00474808
I0204 16:19:46.419888  8495 solver.cpp:258]     Train net output #0: loss = 0.00456668 (* 1 = 0.00456668 loss)
I0204 16:19:46.419895  8495 solver.cpp:571] Iteration 10600, lr = 0.001
I0204 16:19:50.878376  8495 solver.cpp:346] Iteration 10800, Testing net (#0)
I0204 16:19:51.374539  8495 solver.cpp:414]     Test net output #0: accuracy = 0.997042
I0204 16:19:51.374591  8495 solver.cpp:414]     Test net output #1: loss = 0.00723558 (* 1 = 0.00723558 loss)
I0204 16:19:51.384322  8495 solver.cpp:242] Iteration 10800, loss = 0.00458839
I0204 16:19:51.384352  8495 solver.cpp:258]     Train net output #0: loss = 0.0058403 (* 1 = 0.0058403 loss)
I0204 16:19:51.384358  8495 solver.cpp:571] Iteration 10800, lr = 0.001
I0204 16:19:55.841653  8495 solver.cpp:346] Iteration 11000, Testing net (#0)
I0204 16:19:56.338330  8495 solver.cpp:414]     Test net output #0: accuracy = 0.996389
I0204 16:19:56.338371  8495 solver.cpp:414]     Test net output #1: loss = 0.00932889 (* 1 = 0.00932889 loss)
I0204 16:19:56.348062  8495 solver.cpp:242] Iteration 11000, loss = 0.0043335
I0204 16:19:56.348091  8495 solver.cpp:258]     Train net output #0: loss = 0.0031105 (* 1 = 0.0031105 loss)
I0204 16:19:56.348099  8495 solver.cpp:571] Iteration 11000, lr = 0.001
I0204 16:20:00.797082  8495 solver.cpp:346] Iteration 11200, Testing net (#0)
I0204 16:20:01.292757  8495 solver.cpp:414]     Test net output #0: accuracy = 0.996874
I0204 16:20:01.292804  8495 solver.cpp:414]     Test net output #1: loss = 0.00784401 (* 1 = 0.00784401 loss)
I0204 16:20:01.302393  8495 solver.cpp:242] Iteration 11200, loss = 0.00465794
I0204 16:20:01.302418  8495 solver.cpp:258]     Train net output #0: loss = 0.00449505 (* 1 = 0.00449505 loss)
I0204 16:20:01.302426  8495 solver.cpp:571] Iteration 11200, lr = 0.001
I0204 16:20:05.754675  8495 solver.cpp:346] Iteration 11400, Testing net (#0)
I0204 16:20:06.251322  8495 solver.cpp:414]     Test net output #0: accuracy = 0.996862
I0204 16:20:06.251371  8495 solver.cpp:414]     Test net output #1: loss = 0.00776877 (* 1 = 0.00776877 loss)
I0204 16:20:06.260944  8495 solver.cpp:242] Iteration 11400, loss = 0.00446628
I0204 16:20:06.260977  8495 solver.cpp:258]     Train net output #0: loss = 0.00965975 (* 1 = 0.00965975 loss)
I0204 16:20:06.260983  8495 solver.cpp:571] Iteration 11400, lr = 0.001
I0204 16:20:10.721087  8495 solver.cpp:346] Iteration 11600, Testing net (#0)
I0204 16:20:11.217211  8495 solver.cpp:414]     Test net output #0: accuracy = 0.996847
I0204 16:20:11.217249  8495 solver.cpp:414]     Test net output #1: loss = 0.00788995 (* 1 = 0.00788995 loss)
I0204 16:20:11.226686  8495 solver.cpp:242] Iteration 11600, loss = 0.00438179
I0204 16:20:11.226722  8495 solver.cpp:258]     Train net output #0: loss = 0.00509431 (* 1 = 0.00509431 loss)
I0204 16:20:11.226729  8495 solver.cpp:571] Iteration 11600, lr = 0.001
I0204 16:20:15.685344  8495 solver.cpp:346] Iteration 11800, Testing net (#0)
I0204 16:20:16.181651  8495 solver.cpp:414]     Test net output #0: accuracy = 0.996945
I0204 16:20:16.181699  8495 solver.cpp:414]     Test net output #1: loss = 0.00740393 (* 1 = 0.00740393 loss)
I0204 16:20:16.191289  8495 solver.cpp:242] Iteration 11800, loss = 0.00443152
I0204 16:20:16.191319  8495 solver.cpp:258]     Train net output #0: loss = 0.00445073 (* 1 = 0.00445073 loss)
I0204 16:20:16.191326  8495 solver.cpp:571] Iteration 11800, lr = 0.001
I0204 16:20:20.647166  8495 solver.cpp:346] Iteration 12000, Testing net (#0)
I0204 16:20:21.142676  8495 solver.cpp:414]     Test net output #0: accuracy = 0.997046
I0204 16:20:21.142724  8495 solver.cpp:414]     Test net output #1: loss = 0.00731357 (* 1 = 0.00731357 loss)
I0204 16:20:21.152313  8495 solver.cpp:242] Iteration 12000, loss = 0.0043448
I0204 16:20:21.152338  8495 solver.cpp:258]     Train net output #0: loss = 0.0040586 (* 1 = 0.0040586 loss)
I0204 16:20:21.152345  8495 solver.cpp:571] Iteration 12000, lr = 0.001
I0204 16:20:25.608964  8495 solver.cpp:346] Iteration 12200, Testing net (#0)
I0204 16:20:26.104686  8495 solver.cpp:414]     Test net output #0: accuracy = 0.99712
I0204 16:20:26.104735  8495 solver.cpp:414]     Test net output #1: loss = 0.0070898 (* 1 = 0.0070898 loss)
I0204 16:20:26.114198  8495 solver.cpp:242] Iteration 12200, loss = 0.00425709
I0204 16:20:26.114223  8495 solver.cpp:258]     Train net output #0: loss = 0.00199863 (* 1 = 0.00199863 loss)
I0204 16:20:26.114230  8495 solver.cpp:571] Iteration 12200, lr = 0.001
I0204 16:20:30.564534  8495 solver.cpp:346] Iteration 12400, Testing net (#0)
I0204 16:20:31.060662  8495 solver.cpp:414]     Test net output #0: accuracy = 0.996652
I0204 16:20:31.060734  8495 solver.cpp:414]     Test net output #1: loss = 0.00850968 (* 1 = 0.00850968 loss)
I0204 16:20:31.070482  8495 solver.cpp:242] Iteration 12400, loss = 0.00413689
I0204 16:20:31.070511  8495 solver.cpp:258]     Train net output #0: loss = 0.00282972 (* 1 = 0.00282972 loss)
I0204 16:20:31.070519  8495 solver.cpp:571] Iteration 12400, lr = 0.001
I0204 16:20:33.287444  8495 solver.cpp:449] Snapshotting to binary proto file ./model_logs/fcn_iter_12500.caffemodel
I0204 16:20:33.318827  8495 solver.cpp:734] Snapshotting solver state to binary proto file./model_logs/fcn_iter_12500.solverstate
I0204 16:20:35.554111  8495 solver.cpp:346] Iteration 12600, Testing net (#0)
I0204 16:20:36.052384  8495 solver.cpp:414]     Test net output #0: accuracy = 0.996885
I0204 16:20:36.052434  8495 solver.cpp:414]     Test net output #1: loss = 0.00777699 (* 1 = 0.00777699 loss)
I0204 16:20:36.062034  8495 solver.cpp:242] Iteration 12600, loss = 0.00420916
I0204 16:20:36.062072  8495 solver.cpp:258]     Train net output #0: loss = 0.00297095 (* 1 = 0.00297095 loss)
I0204 16:20:36.062088  8495 solver.cpp:571] Iteration 12600, lr = 0.001
I0204 16:20:40.511243  8495 solver.cpp:346] Iteration 12800, Testing net (#0)
I0204 16:20:41.007330  8495 solver.cpp:414]     Test net output #0: accuracy = 0.996917
I0204 16:20:41.007378  8495 solver.cpp:414]     Test net output #1: loss = 0.00764411 (* 1 = 0.00764411 loss)
I0204 16:20:41.016755  8495 solver.cpp:242] Iteration 12800, loss = 0.00418297
I0204 16:20:41.016813  8495 solver.cpp:258]     Train net output #0: loss = 0.00520226 (* 1 = 0.00520226 loss)
I0204 16:20:41.016820  8495 solver.cpp:571] Iteration 12800, lr = 0.001
I0204 16:20:45.470116  8495 solver.cpp:346] Iteration 13000, Testing net (#0)
I0204 16:20:45.965104  8495 solver.cpp:414]     Test net output #0: accuracy = 0.996861
I0204 16:20:45.965219  8495 solver.cpp:414]     Test net output #1: loss = 0.0078293 (* 1 = 0.0078293 loss)
I0204 16:20:45.974683  8495 solver.cpp:242] Iteration 13000, loss = 0.00417772
I0204 16:20:45.974714  8495 solver.cpp:258]     Train net output #0: loss = 0.00326607 (* 1 = 0.00326607 loss)
I0204 16:20:45.974720  8495 solver.cpp:571] Iteration 13000, lr = 0.001
I0204 16:20:50.427384  8495 solver.cpp:346] Iteration 13200, Testing net (#0)
I0204 16:20:50.922801  8495 solver.cpp:414]     Test net output #0: accuracy = 0.997017
I0204 16:20:50.922847  8495 solver.cpp:414]     Test net output #1: loss = 0.0072828 (* 1 = 0.0072828 loss)
I0204 16:20:50.932440  8495 solver.cpp:242] Iteration 13200, loss = 0.00415422
I0204 16:20:50.932476  8495 solver.cpp:258]     Train net output #0: loss = 0.00353188 (* 1 = 0.00353188 loss)
I0204 16:20:50.932492  8495 solver.cpp:571] Iteration 13200, lr = 0.001
I0204 16:20:55.385377  8495 solver.cpp:346] Iteration 13400, Testing net (#0)
I0204 16:20:55.880884  8495 solver.cpp:414]     Test net output #0: accuracy = 0.997108
I0204 16:20:55.880944  8495 solver.cpp:414]     Test net output #1: loss = 0.00710502 (* 1 = 0.00710502 loss)
I0204 16:20:55.890485  8495 solver.cpp:242] Iteration 13400, loss = 0.00419762
I0204 16:20:55.890508  8495 solver.cpp:258]     Train net output #0: loss = 0.00446756 (* 1 = 0.00446756 loss)
I0204 16:20:55.890516  8495 solver.cpp:571] Iteration 13400, lr = 0.001
I0204 16:21:00.347677  8495 solver.cpp:346] Iteration 13600, Testing net (#0)
I0204 16:21:00.843302  8495 solver.cpp:414]     Test net output #0: accuracy = 0.997151
I0204 16:21:00.843349  8495 solver.cpp:414]     Test net output #1: loss = 0.00702075 (* 1 = 0.00702075 loss)
I0204 16:21:00.852957  8495 solver.cpp:242] Iteration 13600, loss = 0.00401714
I0204 16:21:00.852995  8495 solver.cpp:258]     Train net output #0: loss = 0.00450176 (* 1 = 0.00450176 loss)
I0204 16:21:00.853003  8495 solver.cpp:571] Iteration 13600, lr = 0.001
I0204 16:21:05.307443  8495 solver.cpp:346] Iteration 13800, Testing net (#0)
I0204 16:21:05.802575  8495 solver.cpp:414]     Test net output #0: accuracy = 0.996851
I0204 16:21:05.802621  8495 solver.cpp:414]     Test net output #1: loss = 0.00794824 (* 1 = 0.00794824 loss)
I0204 16:21:05.812132  8495 solver.cpp:242] Iteration 13800, loss = 0.00394114
I0204 16:21:05.812168  8495 solver.cpp:258]     Train net output #0: loss = 0.00504493 (* 1 = 0.00504493 loss)
I0204 16:21:05.812176  8495 solver.cpp:571] Iteration 13800, lr = 0.001
I0204 16:21:10.263672  8495 solver.cpp:346] Iteration 14000, Testing net (#0)
I0204 16:21:10.759148  8495 solver.cpp:414]     Test net output #0: accuracy = 0.997012
I0204 16:21:10.759197  8495 solver.cpp:414]     Test net output #1: loss = 0.00750835 (* 1 = 0.00750835 loss)
I0204 16:21:10.768872  8495 solver.cpp:242] Iteration 14000, loss = 0.00405327
I0204 16:21:10.768898  8495 solver.cpp:258]     Train net output #0: loss = 0.00420235 (* 1 = 0.00420235 loss)
I0204 16:21:10.768906  8495 solver.cpp:571] Iteration 14000, lr = 0.001
I0204 16:21:15.224684  8495 solver.cpp:346] Iteration 14200, Testing net (#0)
I0204 16:21:15.722383  8495 solver.cpp:414]     Test net output #0: accuracy = 0.996944
I0204 16:21:15.722476  8495 solver.cpp:414]     Test net output #1: loss = 0.00764293 (* 1 = 0.00764293 loss)
I0204 16:21:15.732236  8495 solver.cpp:242] Iteration 14200, loss = 0.00400832
I0204 16:21:15.732269  8495 solver.cpp:258]     Train net output #0: loss = 0.00487557 (* 1 = 0.00487557 loss)
I0204 16:21:15.732276  8495 solver.cpp:571] Iteration 14200, lr = 0.001
I0204 16:21:20.186553  8495 solver.cpp:346] Iteration 14400, Testing net (#0)
I0204 16:21:20.683812  8495 solver.cpp:414]     Test net output #0: accuracy = 0.996939
I0204 16:21:20.683862  8495 solver.cpp:414]     Test net output #1: loss = 0.00761746 (* 1 = 0.00761746 loss)
I0204 16:21:20.693552  8495 solver.cpp:242] Iteration 14400, loss = 0.00399671
I0204 16:21:20.693578  8495 solver.cpp:258]     Train net output #0: loss = 0.00254239 (* 1 = 0.00254239 loss)
I0204 16:21:20.693585  8495 solver.cpp:571] Iteration 14400, lr = 0.001
I0204 16:21:25.143301  8495 solver.cpp:346] Iteration 14600, Testing net (#0)
I0204 16:21:25.640426  8495 solver.cpp:414]     Test net output #0: accuracy = 0.99711
I0204 16:21:25.640491  8495 solver.cpp:414]     Test net output #1: loss = 0.00711573 (* 1 = 0.00711573 loss)
I0204 16:21:25.650095  8495 solver.cpp:242] Iteration 14600, loss = 0.00400886
I0204 16:21:25.650125  8495 solver.cpp:258]     Train net output #0: loss = 0.0033224 (* 1 = 0.0033224 loss)
I0204 16:21:25.650131  8495 solver.cpp:571] Iteration 14600, lr = 0.001
I0204 16:21:30.123345  8495 solver.cpp:346] Iteration 14800, Testing net (#0)
I0204 16:21:30.627818  8495 solver.cpp:414]     Test net output #0: accuracy = 0.997151
I0204 16:21:30.627867  8495 solver.cpp:414]     Test net output #1: loss = 0.00703559 (* 1 = 0.00703559 loss)
I0204 16:21:30.637462  8495 solver.cpp:242] Iteration 14800, loss = 0.00398847
I0204 16:21:30.637486  8495 solver.cpp:258]     Train net output #0: loss = 0.0031086 (* 1 = 0.0031086 loss)
I0204 16:21:30.637493  8495 solver.cpp:571] Iteration 14800, lr = 0.001
I0204 16:21:35.105904  8495 solver.cpp:449] Snapshotting to binary proto file ./model_logs/fcn_iter_15000.caffemodel
I0204 16:21:35.137672  8495 solver.cpp:734] Snapshotting solver state to binary proto file./model_logs/fcn_iter_15000.solverstate
I0204 16:21:35.154574  8495 solver.cpp:326] Iteration 15000, loss = 0.00660323
I0204 16:21:35.154613  8495 solver.cpp:346] Iteration 15000, Testing net (#0)
I0204 16:21:35.642676  8495 solver.cpp:414]     Test net output #0: accuracy = 0.997152
I0204 16:21:35.642726  8495 solver.cpp:414]     Test net output #1: loss = 0.0070524 (* 1 = 0.0070524 loss)
I0204 16:21:35.642732  8495 solver.cpp:331] Optimization Done.
I0204 16:21:35.642736  8495 caffe.cpp:214] Optimization Done.
